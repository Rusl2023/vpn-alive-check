      - name: Build RU SNI whitelist
        id: build_list
        run: |
          python - <<'EOF'
          import urllib.request
          import urllib.parse
          import os

          URL = "https://github.com/AvenCores/goida-vpn-configs/raw/refs/heads/main/githubmirror/26.txt"

          RU_SNI_WHITELIST = {
              "stats.vk-portal.net",
              "sun6-21.userapi.com",
              "sun6-20.userapi.com",
              "avatars.mds.yandex.net",
              "queuev4.vk.com",
              "sun6-22.userapi.com",
              "sync.browser.yandex.net",
              "top-fwz1.mail.ru",
              "ad.mail.ru",
              "eh.vk.com",
              "akashi.vk-portal.net",
              "sun9-38.userapi.com",
              "st.ozone.ru",
              "ir.ozone.ru",
              "vt-1.ozone.ru",
              "io.ozone.ru",
              "ozone.ru",
              "xapi.ozon.ru",
              "online.sberbank.ru",
              "egress.yandex.net",
              "st.okcdn.ru",
              "rs.mail.ru",
              "splitter.wb.ru",
              "a.wb.ru",
              "servicepipe.ru",
              "alfabank.ru",
              "privacy-cs.mail.ru",
              "imgproxy.cdn-tinkoff.ru",
              "mddc.tinkoff.ru",
              "id.tbank.ru",
              "nspk.ru",
              "login.vk.com",
              "mtscdn.ru",
              "storage.yandexcloud.net",
              "vk.com",
              "www.wildberries.ru",
              "www.ozon.ru",
              "ok.ru",
              "yandex.ru",
              "www.gazprombank.ru",
              "cdn.gpb.ru",
              "www.rzd.ru",
              "www.pochta.ru",
              "www.ivi.ru",
              "hh.ru",
              "www.rbc.ru",
              "pikabu.ru",
              "www.drom.ru",
              "www.drive2.ru",
              "lemanapro.ru"
          }

          print("Downloading 26.txt ...")
          with urllib.request.urlopen(URL, timeout=30) as r:
              lines = r.read().decode("utf-8", errors="ignore").splitlines()

          result = []
          seen = set()

          for line in lines:
              if not line.startswith("vless://"):
                  continue
              try:
                  u = urllib.parse.urlparse(line)
                  q = urllib.parse.parse_qs(u.query)
                  sni = q.get("sni", [""])[0].lower()
                  if sni in RU_SNI_WHITELIST and line not in seen:
                      result.append(line)
                      seen.add(line)
              except Exception:
                  continue

          print(f"Found {len(result)} VLESS links with RU SNI whitelist")

          os.makedirs("githubmirror", exist_ok=True)
          with open("githubmirror/26_ru_whitelist.txt", "w") as f:
              for v in result:
                  f.write(v + "\n")

          with open(os.environ["GITHUB_OUTPUT"], "a") as out:
              out.write(f"count={len(result)}\n")
          EOF
